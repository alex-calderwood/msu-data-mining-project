As if the avalanche of misleading political advertisements wasn't bad enough,internet users were subjected this year to a surge in supposed news storiesabout the presidential race that were even less truthful than the 30-secondspots aired by Donald Trump and Hillary Clinton.These included items claiming that Pope Francis had endorsed Trump, that HillaryClinton sold weapons to Islamic State and that an FBI agent investigatingClinton's emails was killed in a mysterious murder-suicide.This sort of thing goes beyond the complaint on the right that the mainstreammedia favored Clinton by publishing far more stories critical of Trump, or thecomplaint from the left that Trump received uncritical saturation coverage. Thesites in question were circulating stories that they knew weren't true, at timesaided by bots that created huge fake audiences on social media.When surveys by Pew Research Center find that 62 percent of U.S. adults get atleast some of their news from social media, and 20 percent of social-media userssay things they read online have changed their views on an issue or candidate,the electorate is vulnerable to a disinformation campaign. By Buzzfeed's count,the 20 most popular fake-news stories in the last three months of the campaignwere shared more often on Facebook than the top 20 stories from leadingmainstream news sites. Nearly 90 percent of the fake-news stories were pro-Trumpor anti-Clinton, Buzzfeed noted.Some observers argue that the public's receptivity to fake news is a sign thatwe live in a "post-factual" society, with people who are mainly interested ininformation that comports with their preexisting notions. People have beendividing into information tribes with competing echo chambers at least as longas there have been blatantly partisan talk radio stations and cable newschannels. Nor is it new when politicians -- and particularly Republicans -- tryto drive people away from established news sources by accusing them of bias.What's different now is the extent of the polarization, and how vulnerable thesystem is to manipulation. With a vast and growing number of informationsources, people don't automatically discredit a website or a publisher justbecause they've never heard of it. And even the smallest publisher has freeaccess to the global distribution services supplied by search engines and socialmedia networks. Although those are welcome developments for free speech anddiverse viewpoints, they also are a boon to those whose mission is to peddleflat-out falsehoods.Here's another crucial difference: Unlike cable news networks, newspapers orlocal broadcasters, the most powerful distributors of content today -- Facebookand Google search -- do not want to be seen as media companies. They stylethemselves as open platforms, not content gatekeepers.But that description is not quite accurate; both use technology and, in somecases, human editors to shape what they present to the public. And neither iswilling to explain exactly how they do so, other than to say their goal is todeliver the most relevant results possible to individual users. As aconsequence, Facebook prioritizes the material that users see in their "newsfeeds," elevating some of their friends' posts over others. Similarly, Googlepushes some search results higher than others.Executives at both companies said this week that they are working on the problemof fake news, and already have measures in place to cut off the flow ofadvertising dollars to fake-news sites. Yet Facebook arguably made the problemworse this year, when it dumped the editors who helped curate its list of"trending" stories in favor of a more algorithm-driven approach. The change wasmade after former editors said their colleagues had favored mainstream newssources over alternative and conservative sites. But the new approach allowedbogus news items to taint the trending list.It's tempting to say that these platform operators should do more to weed outbad information. But as Facebook CEO Mark Zuckerberg noted, telling thedifference between fact, opinion and fiction is a tricky task. Good reporterscan get things wrong, after all.The fact that Facebook and Google are so powerful is reason enough not to wantthem to become censors. That doesn't mean they can't do more to identify andflag content that readers should question. They can also make it harder forpublishers to game the system in ways that increase the audience for theircontent. Ultimately, though, their technologies rely on their users to elevatecredible material over fantasies. And as long as people cling to the latter overthe former, they're holding the door open to disinformation campaigns andmanipulation.--Los Angeles Times