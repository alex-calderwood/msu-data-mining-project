HIGHLIGHT:Â It's dangerous to promise that a social network will vet what's true.We finally got a grudging mea culpa from Mark Zuckerberg: an admission that fakenews is a significant problem that his social network must help solve.But as a journalist who has been covering the inner workings of the technologyindustry for more than a decade, I find the calls for Facebook to accept broadresponsibility for fact-checking the news, including by hiring editors andreporters, deeply unsettling.What those demanding that Facebook accept "responsibility" for becoming thedominant news aggregator of our time seem to be overlooking is that there's abig difference between the editorial power that individual news organizationswield and that which Facebook could. Such editorial power in Facebook's handswould be unprecedented and dangerous.We can all agree that Facebook should do much more to make sure that blatantlyfabricated claims that Donald J. Trump won the popular vote or received thepope's endorsement don't spread and are, at a minimum, labeled fakes.Facebook admits, and my sources confirm, that it can do a better job of this byhelping users flag dubious articles and predicting fakes based on data it hasfor search. This doesn't have to involve humans: Facebook could decide to labelcontent as suspected as fake if it was flagged a certain number of times and ifit displayed other questionable attributes. Such a move would not meanFacebook's taking broad responsibility for what's true.But hiring editors to enforce accuracy - or even promising to enforce accuracyby partnering with third parties - would create the perception that Facebook ispolicing the "truth," and that is worrisome. The first reason has to do with thenature of Facebook's business. The second has to do with the news business.One thing is clear to anyone who has worked in a newsroom: Not all fact-checkingdecisions are black and white.Did the pope endorse Mr. Trump? He did not.But did the F.B.I. reopen the Hillary Clinton email investigation? That's alittle tougher. Although major news outlets like CNN said that it had, theagency did not in fact reopen the inquiry, which would have been a far moresignificant move than what it did do (which was to take a look at newlydiscovered emails to see if it should reconsider its decision to close thecase). Erroneous reporting by established organizations is a bigger threat thanfabricated stories, and far more rampant.News organizations like my own publication make these judgments a million timesa day. And we sometimes get them wrong. But we are checked by the power of ourcompetitors and, for news organizations with a subscription business, by readerswho stop paying us if we fail them.To be sure, this business model is under great stress as people lose trust innews organizations. But I don't believe the solution is to give up on it,particularly if the alternative is to cede the power of authentication tocompanies like Facebook.I'm not comfortable trusting the truth to one gatekeeper that has a mission anda fiduciary duty to increase advertising revenue, especially when revenue istied more to engagement than information. Facebook continues to consider, forexample, how it can win approval to enter the Chinese market, including bycensoring content. For the company, business can come before truth.No matter how many editors Facebook hired, it would be unable to monitor thevolume of information that flows through its site, and it would be similarlyimpossible for readers to verify what was checked. The minute Facebook acceptsresponsibility for ferreting out misinformation, users will start believing thatit is fact-checking everything on the site.And what about more private content in groups or messages? For that to befact-checked, Facebook users would have to trade their privacy (as an analogy,imagine AT&T fact-checking phone calls). That isn't a position I think Facebookwould ever want to be in.The second reason I am fearful of Facebook as fact checker is what it will do tojournalism.If you don't believe that Facebook's policies could sway the news industry, youhaven't been paying attention over the past five years. Publications have beensuckered into tweaking their content and their business models to try to liveoff the traffic Facebook sends them. They've favored Facebook clicks over theircore readers, and are no closer to addressing plummeting print revenues. Whatwould happen if the distribution of their articles on Facebook was tied tosubmitting data about their sources or conforming to some site-endorsedstandards about what constitutes a trustworthy news source?My fellow reporters and editors will argue that I am letting Facebook off tooeasy. While my husband did work there for a brief period, my position isn't adefense of the company, which I have covered critically for years. I simplydon't trust Facebook, or any one company, with the responsibility fordetermining what is true.Jessica Lessin is the founder and chief executive of The Information.