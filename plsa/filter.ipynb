{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    Filter articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run TreeTagger on the articles we extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/CharlestonGazette-Mail/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)\n",
    "#for file in os.listdir(\"../data/content2/\"):\n",
    "    #if file.endswith(\".txt\"):\n",
    "        #txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/CharlestonGazette-Mail/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/CharlestonGazette-Mail/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/DaytonDailyNews(Ohio)/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)\n",
    "#for file in os.listdir(\"../data/content2/\"):\n",
    "    #if file.endswith(\".txt\"):\n",
    "        #txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/DaytonDailyNews(Ohio)/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/DaytonDailyNews(Ohio)/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/LosAngelesTimes/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)\n",
    "#for file in os.listdir(\"../data/content2/\"):\n",
    "    #if file.endswith(\".txt\"):\n",
    "        #txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/LosAngelesTimes/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/LosAngelesTimes/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/LowellSun(Massachusetts)/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)\n",
    "#for file in os.listdir(\"../data/content2/\"):\n",
    "    #if file.endswith(\".txt\"):\n",
    "        #txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/LowellSun(Massachusetts)/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/LowellSun(Massachusetts)/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/NewYorkObserver/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/NewYorkObserver/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/NewYorkObserver/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/PittsburghPost-Gazette/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/PittsburghPost-Gazette/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/PittsburghPost-Gazette/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/SanBernardinoSun(California)/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/SanBernardinoSun(California)/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/SanBernardinoSun(California)/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/SanGabrielValleyTribune(California)/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/SanGabrielValleyTribune(California)/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/SanGabrielValleyTribune(California)/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "txt=[]\n",
    "for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/TheNewYorkTimes/\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txt.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_in = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/TheNewYorkTimes/'\n",
    "#path_in2 = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/data/content2/'\n",
    "path_out = 'c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/TheNewYorkTimes/'\n",
    "os.chdir(\"c:/TreeTagger/\")\n",
    "\n",
    "for i in range(0,len(txt)) : \n",
    "    os.system('tag-english '+path_in+txt[i]+' > '+path_out+txt[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter after TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from sortedcontainers import SortedDict\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "df = SortedDict(defaultdict(int))\n",
    "\n",
    "list_folder = ['CharlestonGazette-Mail','DaytonDailyNews(Ohio)','LosAngelesTimes','LowellSun(Massachusetts)','NewYorkObserver','PittsburghPost-Gazette','SanBernardinoSun(California)','SanGabrielValleyTribune(California)','TheNewYorkTimes']\n",
    "list_sc = [\",\",\".\",\"-\",\"?\",\"_\",\"[\",\"]\",\"(\",\")\",\"{\",\"}\",\":\",\"!\",\";\",\"\\'\",\"\\\"\",\"/\",\"#\",'\\n','\\r','\\t','>','<','...','>>>']\n",
    "\n",
    "for f in list_folder : \n",
    "    \n",
    "    txt=[]\n",
    "    for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+\"/TT/\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            txt.append(file)\n",
    "    for i in range(0, len(txt)):\n",
    "        #Open txt file and read it\n",
    "        txtfile=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+\"/TT/\"+txt[i])\n",
    "        content = txtfile.read()\n",
    "        txtfile.close()\n",
    "    \n",
    "        #Remove accents\n",
    "        #text1 = content.encode('utf-8')\n",
    "        #Remove punctuations\n",
    "        #text_sans_punct = ''.join([k if k not in list_sc else ' ' for k in content ])\n",
    "        text_list_lignes= content.split('\\n')\n",
    "    \n",
    "        map_txt = SortedDict(defaultdict(int))\n",
    "        for j in range(0,len(text_list_lignes)) :\n",
    "            text_ligne = text_list_lignes[j].split('\\t')\n",
    "        \n",
    "            if len(text_ligne) == 3 and text_ligne[2] == '@card@' : \n",
    "                map_txt.setdefault(text_ligne[0],0)\n",
    "                map_txt[text_ligne[0]] += 1\n",
    "            elif len(text_ligne) == 1 : \n",
    "                None \n",
    "            elif text_ligne[1] == 'PUN:cit' : \n",
    "                map_txt.setdefault('\\\"',0)\n",
    "                map_txt['\\\"'] +=1   \n",
    "            else : \n",
    "                word = text_ligne[2].lower()\n",
    "                map_txt.setdefault(word,0)\n",
    "                map_txt[word] += 1\n",
    "        if '' in map_txt : \n",
    "            del(map_txt[''])\n",
    "\n",
    "        #Write the words in a file\n",
    "        txtfile=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+\"/Filter/\"+txt[i],'w')\n",
    "        for key in map_txt : \n",
    "            txtfile.write(key+' '+str(map_txt[key])+'\\n')\n",
    "            df.setdefault(key,0)\n",
    "            df[key] +=1\n",
    "            #tf.setdefault(key,0)\n",
    "            #tf[key] += map_txt[key]\n",
    "        txtfile.close() \n",
    "        \n",
    "            #Write the voc and df in a file\n",
    "    txt_voc=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+'/voc.txt','w')\n",
    "    txt_df=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+'/df.txt','w')\n",
    "\n",
    "    index = 1\n",
    "    for key in df : \n",
    "        txt_voc.write(str(index)+' '+key+'\\n')\n",
    "        txt_df.write(key+' '+str(df[key])+'\\n')\n",
    "        index += 1\n",
    "\n",
    "    txt_voc.close()\n",
    "    txt_df.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector rpz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharlestonGazette-Mail\n",
      "DaytonDailyNews(Ohio)\n",
      "LosAngelesTimes\n",
      "LowellSun(Massachusetts)\n",
      "NewYorkObserver\n",
      "PittsburghPost-Gazette\n",
      "SanBernardinoSun(California)\n",
      "SanGabrielValleyTribune(California)\n",
      "TheNewYorkTimes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sortedcontainers import SortedDict\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "list_folder = ['CharlestonGazette-Mail','DaytonDailyNews(Ohio)','LosAngelesTimes','LowellSun(Massachusetts)','NewYorkObserver','PittsburghPost-Gazette','SanBernardinoSun(California)','SanGabrielValleyTribune(California)','TheNewYorkTimes']\n",
    "\n",
    "for f in list_folder : \n",
    "    print(f)\n",
    "    txt=[]\n",
    "    for file in os.listdir(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+\"/Filter/\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            txt.append(file)\n",
    "\n",
    "    voc = SortedDict(defaultdict(int))\n",
    "\n",
    "\n",
    "    vocfile=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+'/voc.txt')\n",
    "    content = vocfile.read()\n",
    "    vocfile.close()\n",
    "    lignes= content.split('\\n')\n",
    "\n",
    "    for i in range(0, len(lignes)) : \n",
    "        word = lignes[i].split(' ')\n",
    "        if len(word) == 2 : \n",
    "            voc[word[1]] = word[0]\n",
    "\n",
    "    rpzfile=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+'/representation_tf.txt','w')\n",
    "\n",
    "    for i in range(0, len(txt)):\n",
    "        #Open txt file and read it\n",
    "        txtfile=open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/\"+f+'/Filter/'+txt[i])\n",
    "        content = txtfile.read()\n",
    "        txtfile.close()\n",
    "        lignes= content.split('\\n')\n",
    "        #print(txt[i])\n",
    "        for j in range(0,len(lignes)) :\n",
    "            word = lignes[j].split(' ')\n",
    "            if len(word) == 2 : \n",
    "                rpzfile.write(voc[word[0]]+':'+str(word[1])+' ')\n",
    "        rpzfile.write('\\n')\n",
    "    rpzfile.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedDict\n",
    "voc = SortedDict()\n",
    "\n",
    "with open(\"c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/TheNewYorkTimes/voc.txt\", 'r') as voc_file:\n",
    "    for line in voc_file:\n",
    "        line = line.replace('\\n', '')\n",
    "        word = line.split(' ')\n",
    "        voc[word[0]] = word[1]\n",
    "        \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "txtfile = open('c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/TheNewYorkTimes/phi_mat.txt','r')\n",
    "content = txtfile.read()\n",
    "txtfile.close()\n",
    "\n",
    "#saving topics\n",
    "htmlfile = open('c:/Users/Sara/Documents/GitHub/DataMining/msu-data-mining-project/plsa/TreeTagger/TheNewYorkTimes/topics.html','w')\n",
    "#write head\n",
    "htmlfile.write('<!DOCTYPE html>\\n<html lang=\"fr\">\\n<head>\\n<title>Liste des 20 topics</title>\\n</head>\\n<body>\\n')\n",
    "#write body \n",
    "\n",
    "topic_transp = list()\n",
    "phi_table = content.split(' \\n')\n",
    "for i in range(0, len(phi_table)):\n",
    "    phi_raw = phi_table[i].split(' ')\n",
    "    topic_transp.append(phi_raw)\n",
    "\n",
    "topic = list()\n",
    "for i in range(0,20):\n",
    "    ligne = list()\n",
    "    for j in range(0,len(phi_table)-1):\n",
    "        ligne.append(float((topic_transp[j])[i]))\n",
    "    topic.append(ligne)\n",
    "\n",
    "for t in range(0,len(topic)):   \n",
    "    x = np.array(topic[t])\n",
    "    res_temp = np.argsort(x)\n",
    "    res = np.flipud(res_temp)\n",
    "    for j in range(0,50):\n",
    "        if j == 0 : \n",
    "            htmlfile.write('<section>\\n<h1> Topic'+str(t+1)+'</h1>\\n<ul>')\n",
    "        htmlfile.write('<li>'+voc[str(res[j]+1)]+'</li>\\n')\n",
    "    htmlfile.write('</ul>\\n</section>\\n')\n",
    "\n",
    "htmlfile.write('\\n</body>\\n</html>')\n",
    "htmlfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
